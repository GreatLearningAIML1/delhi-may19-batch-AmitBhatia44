{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idFln8hllfmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorflow==2.0.0 --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiVU-Xz5pehR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ad82ddf2-9764-4e38-c14f-7a28369ff7cf"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0d2167e3-db30-4d5b-92da-c08a2986017a"
      },
      "source": [
        "pd.DataFrame(y_train).nunique()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    10\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uOmgX1IuSsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "965dc783-fad2-4f34-9644-d97648d6ea04"
      },
      "source": [
        "print('--- THE DATA ---')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- THE DATA ---\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "f1552b41-ca0e-40a2-97ff-13c479b922ff"
      },
      "source": [
        "\n",
        "    # Define model\n",
        "    model1 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model1.add(Convolution2D(32, 3, 3))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model1.add(Flatten())\n",
        "    model1.add(Dense(128))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model1.add(Dense(10))\n",
        "    model1.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model1\n",
        "    model1.fit(x_train, y_train, batch_size=32, nb_epoch=10, \n",
        "              validation_data=(x_test, y_test))\n",
        "  "
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.3715 - acc: 0.8660 - val_loss: 0.2805 - val_acc: 0.9014\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.2287 - acc: 0.9165 - val_loss: 0.2607 - val_acc: 0.9048\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.1673 - acc: 0.9378 - val_loss: 0.2742 - val_acc: 0.9049\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.1196 - acc: 0.9557 - val_loss: 0.2763 - val_acc: 0.9148\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0817 - acc: 0.9695 - val_loss: 0.2897 - val_acc: 0.9149\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0565 - acc: 0.9792 - val_loss: 0.3310 - val_acc: 0.9163\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0396 - acc: 0.9858 - val_loss: 0.3978 - val_acc: 0.9139\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0305 - acc: 0.9891 - val_loss: 0.4449 - val_acc: 0.9110\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 0.0237 - acc: 0.9915 - val_loss: 0.4525 - val_acc: 0.9159\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0225 - acc: 0.9917 - val_loss: 0.4781 - val_acc: 0.9122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15810e0358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo1QZueWx6NZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ac49bf57-62f4-4996-98fe-c53bacd41720"
      },
      "source": [
        "loss_and_metrics = model1.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 50us/step\n",
            "[0.4780556729733944, 0.9122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "aafda61e-4dd1-4b4f-b5ee-f96413d89679"
      },
      "source": [
        "\n",
        "    # Define model\n",
        "    model2 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # Max Pooling\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    # Dropout\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(128))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model2.add(Dense(10))\n",
        "    model2.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model2\n",
        "    model2.fit(x_train, y_train, batch_size=32, nb_epoch=10, \n",
        "              validation_data=(x_test, y_test))\n",
        "  "
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.3940 - acc: 0.8594 - val_loss: 0.3145 - val_acc: 0.8860\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.2582 - acc: 0.9061 - val_loss: 0.2820 - val_acc: 0.8972\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.2115 - acc: 0.9218 - val_loss: 0.2375 - val_acc: 0.9117\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.1753 - acc: 0.9345 - val_loss: 0.2534 - val_acc: 0.9115\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.1490 - acc: 0.9441 - val_loss: 0.2238 - val_acc: 0.9210\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.1239 - acc: 0.9540 - val_loss: 0.2244 - val_acc: 0.9241\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.1107 - acc: 0.9581 - val_loss: 0.2438 - val_acc: 0.9230\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0908 - acc: 0.9653 - val_loss: 0.2753 - val_acc: 0.9227\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0812 - acc: 0.9691 - val_loss: 0.2805 - val_acc: 0.9246\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0685 - acc: 0.9743 - val_loss: 0.2847 - val_acc: 0.9240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1580e12940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkgQfD3k0mBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "038ab826-527d-40a2-eb1b-de466fa9a4a5"
      },
      "source": [
        "loss_and_metrics = model2.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 50us/step\n",
            "[0.2847382840484381, 0.924]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.01,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.01,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "# Prepare the generator\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "68e41057-71f8-4688-a819-7144250604e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "0dd89f57-1fe4-443f-9639-673b7c948c24"
      },
      "source": [
        "\n",
        "    # Define model\n",
        "    model3 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # Max Pooling\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    # Dropout\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model3.add(Flatten())\n",
        "    model3.add(Dense(128))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model3.add(Dense(10))\n",
        "    model3.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model3\n",
        "    model3.fit_generator(datagen.flow(x_train, y_train,batch_size=32),\n",
        "                    samples_per_epoch=x_train.shape[0],\n",
        "                    nb_epoch=10,\n",
        "                    validation_data=(x_test, y_test), callbacks=callback_list)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.6216 - acc: 0.7725 - val_loss: 0.4607 - val_acc: 0.8351\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4352 - acc: 0.8400 - val_loss: 0.4231 - val_acc: 0.8526\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3870 - acc: 0.8574 - val_loss: 0.3753 - val_acc: 0.8675\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3528 - acc: 0.8708 - val_loss: 0.3679 - val_acc: 0.8741\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3328 - acc: 0.8781 - val_loss: 0.3269 - val_acc: 0.8837\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3131 - acc: 0.8848 - val_loss: 0.3309 - val_acc: 0.8801\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3040 - acc: 0.8885 - val_loss: 0.3096 - val_acc: 0.8907\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2901 - acc: 0.8953 - val_loss: 0.3050 - val_acc: 0.8975\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2840 - acc: 0.8952 - val_loss: 0.2920 - val_acc: 0.8954\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2774 - acc: 0.8972 - val_loss: 0.3013 - val_acc: 0.8954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1580be6fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "339fc95a-fefe-4190-9846-acac9037dcb1"
      },
      "source": [
        "loss_and_metrics = model3.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 51us/step\n",
            "[0.301311632168293, 0.8954]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Already imported above"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8320b363-af27-4f20-c88e-394f6456f973"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v7tkqBV7csf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "56bbf81e-095d-4f4f-e693-44695ed3dc85"
      },
      "source": [
        "pd.DataFrame(Y_train).nunique()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    10\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r4a48Xr68Qnu",
        "colab": {}
      },
      "source": [
        "Y_train = tf.keras.utils.to_categorical(Y_train, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vak7HaOR8Qn2",
        "colab": {}
      },
      "source": [
        "Y_test = tf.keras.utils.to_categorical(Y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84TACTa_8QoJ"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XVCHr_na8QoM",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "468ab97d-08b4-4dcd-b6a5-bac358d637ec",
        "id": "fZnNchk98QoU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('--- THE DATA ---')\n",
        "print('X_train shape:', x_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- THE DATA ---\n",
            "X_train shape: (60000, 28, 28, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This will do preprocessing and realtime data augmentation:\n",
        "data_gen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.01,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.01,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=True)  # randomly flip images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSw8Bv2_4hb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the generator\n",
        "data_gen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "0d6d5c5d-9297-4f70-83b4-8aa9d1bbb008"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen1 = data_gen.flow(X_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen1.next().squeeze())\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}